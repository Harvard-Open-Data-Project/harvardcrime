{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'timing' from 'timing.pyc'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pdfquery\n",
    "\n",
    "import incident\n",
    "reload(incident)\n",
    "from incident import Incident\n",
    "import timing\n",
    "reload(timing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_from_curve(ltcurve):\n",
    "    # text can be within LTTextBoxHorizontal or LTTextLineHorizontal\n",
    "    # the problem is that these are interleaved\n",
    "    # so we select EITHER as they come\n",
    "    # if we chose the Boxes first and the Lines second then merged those lists,\n",
    "    # the resulting list would be out of order!\n",
    "    # e.g. if the true order is B1 L1 B2 B3 L2, the approach we are using\n",
    "    # gives you the right order... but choosing Boxes and Lines separately\n",
    "    # gives you B1 B2 B3 L1 L2!!!!\n",
    "    textual_elements = ltcurve.cssselect(\"LTTextBoxHorizontal, LTTextLineHorizontal\")\n",
    "    texts = [t.text.strip() for t in textual_elements]\n",
    "    \n",
    "    # remove empty lines\n",
    "    cleaned_texts = [t for t in texts if t != '']\n",
    "    \n",
    "    # PROBLEM with this approach: in rare cases some text from this falls way\n",
    "    # outside the ltcurve. Might it still be within the bounding box though?\n",
    "    \n",
    "    # UPDATE: try gathering all data\n",
    "    # for 11/28 consider these bboxes\n",
    "    #\n",
    "    # 10:08am [247.08, 80.197, 275.587, 90.18]\n",
    "    # hp laptop [6.0, 65.784, 737.868, 82.318]\n",
    "    # bounding box [3.36, 77.7, 754.86, 98.64]\n",
    "    \n",
    "    return cleaned_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "\n",
    "def dump_csv(incidents):\n",
    "    \"\"\"\n",
    "    Dumps a list of Incident objects to CSV.\n",
    "    \"\"\"\n",
    "    with open('harvard_crime_incidents.csv', 'w') as csvfile:\n",
    "        fieldnames = Incident.CSV_FIELDS\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "        writer.writeheader()\n",
    "\n",
    "        for incident in incidents:\n",
    "            writer.writerow(incident.to_dict_for_csv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def incidents_of_pdf(pdf_file):\n",
    "    \"\"\"\n",
    "    Pass this function the result of a pdfquery.PDFQuery() function.\n",
    "    This will read through the pdf file and return a list of \n",
    "    Incident objects contained in there!\n",
    "    \n",
    "    Make sure the PDF is load()'ed before you pass it.\n",
    "    \"\"\"\n",
    "    \n",
    "    # TODO watch out for things like 11/24/17 where there were no incidents. there's a specific tag for those.\n",
    "    \n",
    "    # so each individual report, as well as headers, is filed inside \n",
    "    # its own <LTCurve>. The text fields are inside <LTTextLineHorizontal>s and <LTTextBoxHorizontal>s\n",
    "    # inside the <LTCurve>.\n",
    "    reports_plus_heads = pdf.tree.findall(\".//LTCurve\")\n",
    "    \n",
    "    # extract raw incidents\n",
    "    raw_incidents = [get_text_from_curve(lt) for lt in reports_plus_heads]\n",
    "\n",
    "    # remove headers of tables\n",
    "    HEADER_ROW_TEXT = ['Reported', 'Incident Type', 'Occurred', 'Location', 'Disposition']\n",
    "    incidents_without_headers = [i for i in raw_incidents if i != HEADER_ROW_TEXT]\n",
    "    \n",
    "    # convert incidents to proper objects\n",
    "    # 9 = proper length of report; anything less is malformed\n",
    "    # TODO clean up â€” extract error checking into its own make_incident_objects() function\n",
    "    incident_objects = [incident.Incident(i) for i in incidents_without_headers if len(i) == 9]\n",
    "    \n",
    "    return incident_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = pdfquery.PDFQuery(\"data/112817.pdf\")\n",
    "pdf.load()\n",
    "all_incidents = incidents_of_pdf(pdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try another date\n",
    "pdf = pdfquery.PDFQuery(\"data/113017.pdf\")\n",
    "pdf.load()\n",
    "new_incidents = incidents_of_pdf(pdf)\n",
    "all_incidents += new_incidents\n",
    "dump_csv(all_incidents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# REMAINING TODOS:\n",
    "# - have a function to programmatically download HUPD crime logs\n",
    "# - have another function to run through all downloaded crime logs in the `data` folder\n",
    "#   (requires us to read the file system?)\n",
    "# - Extract the descriptive test along with the metadata. This is somewhat harder but still\n",
    "#   very important!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
