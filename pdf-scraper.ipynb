{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils' from '/Users/neel/Git/harvardcrime/utils.py'>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import pdfquery\n",
    "\n",
    "import incident\n",
    "reload(incident)\n",
    "from incident import Incident\n",
    "import timing\n",
    "reload(timing)\n",
    "import utils\n",
    "reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_from_curve(ltcurve):\n",
    "    # text can be within LTTextBoxHorizontal or LTTextLineHorizontal\n",
    "    # the problem is that these are interleaved\n",
    "    # so we select EITHER as they come\n",
    "    # if we chose the Boxes first and the Lines second then merged those lists,\n",
    "    # the resulting list would be out of order!\n",
    "    # e.g. if the true order is B1 L1 B2 B3 L2, the approach we are using\n",
    "    # gives you the right order... but choosing Boxes and Lines separately\n",
    "    # gives you B1 B2 B3 L1 L2!!!!\n",
    "    textual_elements = ltcurve.cssselect(\"LTTextBoxHorizontal, LTTextLineHorizontal\")\n",
    "    texts = [t.text.strip() for t in textual_elements]\n",
    "    \n",
    "    # remove empty lines\n",
    "    cleaned_texts = [t for t in texts if t != '']\n",
    "    \n",
    "    # PROBLEM with this approach: in rare cases some text from this falls way\n",
    "    # outside the ltcurve. Might it still be within the bounding box though?\n",
    "    \n",
    "    # UPDATE: try gathering all data\n",
    "    # for 11/28 consider these bboxes\n",
    "    #\n",
    "    # 10:08am [247.08, 80.197, 275.587, 90.18]\n",
    "    # hp laptop [6.0, 65.784, 737.868, 82.318]\n",
    "    # bounding box [3.36, 77.7, 754.86, 98.64]\n",
    "    \n",
    "    return cleaned_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def incidents_of_pdf(pdf_file):\n",
    "    \"\"\"\n",
    "    Pass this function the result of a pdfquery.PDFQuery() function.\n",
    "    This will read through the pdf file and return a list of \n",
    "    Incident objects contained in there!\n",
    "    \n",
    "    Make sure the PDF is load()'ed before you pass it.\n",
    "    \"\"\"\n",
    "    \n",
    "    # TODO watch out for things like 11/24/17 where there were no incidents. there's a specific tag for those.\n",
    "    \n",
    "    # so each individual report, as well as headers, is filed inside \n",
    "    # its own <LTCurve>. The text fields are inside <LTTextLineHorizontal>s and <LTTextBoxHorizontal>s\n",
    "    # inside the <LTCurve>.\n",
    "    reports_plus_heads = pdf.tree.findall(\".//LTCurve\")\n",
    "    \n",
    "    # extract raw incidents\n",
    "    raw_incidents = [get_text_from_curve(lt) for lt in reports_plus_heads]\n",
    "\n",
    "    # remove headers of tables\n",
    "    HEADER_ROW_TEXT = ['Reported', 'Incident Type', 'Occurred', 'Location', 'Disposition']\n",
    "    incidents_without_headers = [i for i in raw_incidents if i != HEADER_ROW_TEXT]\n",
    "    \n",
    "    # convert incidents to proper objects\n",
    "    # 9 = proper length of report; anything less is malformed\n",
    "    # TODO clean up â€” extract error checking into its own make_incident_objects() function\n",
    "    incident_objects = [incident.Incident(i) for i in incidents_without_headers if len(i) == 9]\n",
    "    \n",
    "    return incident_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = pdfquery.PDFQuery(\"data/112817.pdf\")\n",
    "pdf.load()\n",
    "all_incidents = incidents_of_pdf(pdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try another date\n",
    "pdf = pdfquery.PDFQuery(\"data/113017.pdf\")\n",
    "pdf.load()\n",
    "new_incidents = incidents_of_pdf(pdf)\n",
    "all_incidents += new_incidents\n",
    "utils.dump_csv(all_incidents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMAINING TODOS:\n",
    "# - have a function to programmatically download HUPD crime logs\n",
    "# - have another function to run through all downloaded crime logs in the `data` folder\n",
    "#   (requires us to read the file system?)\n",
    "# - Extract the descriptive test along with the metadata. This is somewhat harder but still\n",
    "#   very important!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done data/012018.pdf\n",
      "Done data/010418.pdf\n",
      "Done data/020518.pdf\n",
      "Done data/110817.pdf\n",
      "Done data/020718.pdf\n",
      "Done data/010618.pdf\n",
      "Done data/012218.pdf\n",
      "Done data/112817.pdf\n",
      "Done data/122917.pdf\n",
      "Done data/012618.pdf\n",
      "Done data/123017.pdf\n",
      "Done data/010218.pdf\n",
      "Done data/020318.pdf\n",
      "Done data/020118.pdf\n",
      "Done data/011918.pdf\n",
      "Done data/012418.pdf\n",
      "Done data/020618.pdf\n",
      "Done data/010718.pdf\n",
      "Done data/012118.pdf\n",
      "Done data/010518.pdf\n",
      "Done data/020418.pdf\n",
      "Done data/010118.pdf\n",
      "Done data/012518.pdf\n",
      "Done data/011818.pdf\n",
      "Done data/012718.pdf\n",
      "Done data/122817.pdf\n",
      "Done data/010318.pdf\n",
      "Done data/020218.pdf\n",
      "Done data/113017.pdf\n",
      "Done data/123117.pdf\n",
      "Done data/122417.pdf\n",
      "Done data/121917.pdf\n",
      "Done data/011618.pdf\n",
      "Done data/011418.pdf\n",
      "Done data/012918.pdf\n",
      "Done data/122617.pdf\n",
      "Done data/013018.pdf\n",
      "Done data/010918.pdf\n",
      "Done data/020818.pdf\n",
      "Done data/011018.pdf\n",
      "Done data/021118.pdf\n",
      "Done data/122217.pdf\n",
      "Done data/122017.pdf\n",
      "Done data/021318.pdf\n",
      "Done data/011218.pdf\n",
      "Done data/122717.pdf\n",
      "Done data/012818.pdf\n",
      "Done data/021418.pdf\n",
      "Done data/011518.pdf\n",
      "Done data/013118.pdf\n",
      "Done data/011718.pdf\n",
      "Done data/121817.pdf\n",
      "Done data/112417.pdf\n",
      "Done data/122517.pdf\n",
      "Done data/021218.pdf\n",
      "Done data/011318.pdf\n",
      "Done data/122117.pdf\n",
      "Done data/010818.pdf\n",
      "Done data/020918.pdf\n",
      "Done data/122317.pdf\n",
      "Done data/011118.pdf\n",
      "Done data/021018.pdf\n"
     ]
    }
   ],
   "source": [
    "# Go through EVERY pdf in our data folder!\n",
    "import glob\n",
    "\n",
    "all_incidents = []\n",
    "\n",
    "for filename in glob.iglob('data/*.pdf'):\n",
    "    # filename will be like `data/xxxxxx.pdf`\n",
    "    # extract incidents from this file\n",
    "    pdf = pdfquery.PDFQuery(filename)\n",
    "    pdf.load()\n",
    "    new_incidents = incidents_of_pdf(pdf)\n",
    "    all_incidents += new_incidents\n",
    "    \n",
    "    print(\"Done {}\".format(filename))\n",
    "    \n",
    "# dump to csv\n",
    "utils.dump_csv(all_incidents)\n",
    "print(\"Dumped!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "crime",
   "language": "python",
   "name": "crime"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
